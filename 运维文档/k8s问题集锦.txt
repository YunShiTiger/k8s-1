1、Pod偶尔存活检查失败
现象:
Pod偶尔存活检查失败，导致Pod重启，业务偶尔连接异常。
排错:
      之前从未遇到这种情况，经排查发现那段时间的流量很大，推测跟连接数或并发量有关。对比了一下生产与测试环境的差异，最后发现是tcp_max_syn_backlog大小导致的。
TCP 连接建立会经过三次握手，server 收到 SYN 后会将连接加入 SYN 队列，当收到最后一个 ACK 后连接建立，这时会将连接从 SYN 队列中移动到ACCEPT 队列。
在 SYN 队列中的连接都是没有建立完全的连接，处于半连接状态。如果 SYN 队列比较小，而短时间内并发新建的连接比较多，同时处于半连接状态的连接就多，
SYN 队列就可能溢出，导致部分新连接无法建立。tcp_max_syn_backlog可以控制syn队列大小，改成 8096 后就可以解决问题。



2、部分节点无法启动pod
有时候，我们部署了应用之后，发现在部分工作节点上pod无法启动（一直处于ContainerCreating的状态）：

通过排查日志最终我们得到重要信息如下所示：

NetworkPlugin cni failed to set up pod "demo-deployment-675b5f9477-hdcwg_default" network: failed to set bridge addr: \
"cni0" already has an IP address different from 10.0.2.1/24
这是由于当前节点之前被反复注册，导致flannel网络出现问题。可以依次执行以下脚本来重置节点并且删除flannel网络来解决：


3、最近研发新上一个微服务，上线后启动了6个Pod，运行一段时间后一直很稳定，但有一天用户访问有问题，在手机端打开直接提示“网络错误”。

分析解决：对于这个报错，研发那边的反馈是运维环境有问题，网络不稳定造成的，但我们实际的生产环境是在K8s上，每个node都在一个网络内，而且都是内网通讯，如果是网络原因，那应该也会影响其他项目的pod,但从现象看，别的同Node节点的服务运行稳定，查了日志，也没有任何报错，后来经过排查，发现这6个pod，在运行一段时间后有那么2~3个pod会出现假死状态，就是说pod显示是运行状态，但实际上已经无法处理外部请求了，因为是新服务，上线的时候并没有配置Liveness probe, readness probe, 在这种情况下，因为没有这些检测，service并不知道某个pod有问题，所以请求还是会转发到该Pod上，这样就导致了用户出现问题

解决：给这个服务配置存活和就绪检查，问题到这里就结束了，在最后我想说的是：给每个服务上线配置存活检测和就绪检查真的很基础也很重要，尤其是生产环境，一定要配置，别重蹈覆辙，因为这样即使是程序有问题，也不会影响到用户端的访问，当然这个程序突然就不工作假死的问题研发也在查代码解决，但从客户访问角度运维已经解决了问题。 

4、我们服务一直是采用滚动更新策略在进行更新，而且是晚上时段进行大版本的更新迭代，一直也没有什么影响，但最近用途突增，晚上用户量也很大，别的合作方在使用我们api接口时会有报错，影响了他们使用。

分析：  这种问题还是得查日志，查到最后我们在nginx日志里发现了在更新的时间段的确是有几条错误日志，时间跟我们更新的时间段相匹配，那按说采用滚动更新模式在加配置了探针，理论上应该不会出现这种问题，所以跟研发对了下，通过日志里访问的记录，得出这几个都是比较耗时的长连接，那么问题就来了，因为在滚动更新时，正在更新的pod是不会有新请求进来，因为配置了探针，但一旦更新完一个pod，老的pod就会被杀掉， 那么在杀掉这个pod上如果还存在这连接业务没有处理完，就会被断开，因为pod没了，问题到这里就清晰了。

解决： 解决这个问题就要增加pod生命周期钩子，在pod被销毁前给出一段时间让该pod把业务处理完。那到底设置多长时间？10秒还是30秒，这个没有确切的答案，数字只能根据实际业务来，但设置太长也不好，会让人产生误解pod停不掉了。另外我再说一个这个钩子的应用场景，就是在做HPA的时候，扩容的时候不会有问题，但在缩容的时候也会存在很多已经存在在pod上的连接还没来得及处理pod就被销毁的问题，这个也会对生产环境产生影响，这时候就必须要配置生命周期钩子了，这样才能保障在缩容的情况下业务是稳定用户无感知的。 










3、最近在安装生成环境，遇到一个内存爆掉的问题。k8s集群环境下，搭建web应用，采用java -jar 方式启动springboot项目。

java虚拟机在没有设置使用内存的情况下，默认占用系统1/4的内存。pod中执行也是一样的，jvm识别是物理主机的内存，而不是k8s给pod分配的内存。因此在没有给jvm指定的情况下，由于生产环境物机器性能较好，物理内存很大，jvm默认占用的内存超出了k8s分配给pod的内存，导致pod内存溢出，从而k8s自动重启pod。


4、LVS、Nginx、HAproxy有什么区别？工作中你怎么选择？
LVS： 是基于四层的转发
HAproxy： 是基于四层和七层的转发，是专业的代理服务器
Nginx： 是WEB服务器，缓存服务器，又是反向代理服务器，可以做七层的转发

区别： LVS由于是基于四层的转发所以只能做端口的转发
而基于URL的、基于目录的这种转发LVS就做不了

工作选择：

HAproxy和Nginx由于可以做七层的转发，所以URL和目录的转发都可以做
在很大并发量的时候我们就要选择LVS，像中小型公司的话并发量没那么大
选择HAproxy或者Nginx足已，由于HAproxy由是专业的代理服务器
配置简单，所以中小型企业推荐使用HAproxy


18、lvs/nginx/haproxy优缺点

Nginx的优点是：

1、工作在网络的7层之上，可以针对http应用做一些分流的策略，比如针对域名、目录结构
它的正则规则比HAProxy更为强大和灵活，这也是它目前广泛流行的主要原因之一

2、Nginx对网络稳定性的依赖非常小，理论上能ping通就就能进行负载功能，这个也是它的优势之一
相反LVS对网络稳定性依赖比较大，这点本人深有体会；

3、Nginx安装和配置比较简单，测试起来比较方便，它基本能把错误用日志打印出来
LVS的配置、测试就要花比较长的时间了，LVS对网络依赖比较大。

4、可以承担高负载压力且稳定，在硬件不差的情况下一般能支撑几万次的并发量，负载度比LVS相对小些。

5、Nginx可以通过端口检测到服务器内部的故障，比如根据服务器处理网页返回的状态码、超时等等，并且会把返回错误的请求重新提交到另一个节点，不过其中缺点就是不支持url来检测。比如用户正在上传一个文件，而处理该上传的节点刚好在上传过程中出现故障，Nginx会把上传切到另一台服务器重新处理，而LVS就直接断掉了，如果是上传一个很大的文件或者很重要的文件的话，用户可能会因此而不满。

6、Nginx不仅仅是一款优秀的负载均衡器/反向代理软件，它同时也是功能强大的Web应用服务器
LNMP也是近几年非常流行的web架构，在高流量的环境中稳定性也很好。

7、Nginx现在作为Web反向加速缓存越来越成熟了，速度比传统的Squid服务器更快，可考虑用其作为反向代理加速器

8、Nginx可作为中层反向代理使用，这一层面Nginx基本上无对手，唯一可以对比Nginx的就只有lighttpd了
不过lighttpd目前还没有做到Nginx完全的功能，配置也不那么清晰易读，社区资料也远远没Nginx活跃

9、Nginx也可作为静态网页和图片服务器，这方面的性能也无对手。还有Nginx社区非常活跃，第三方模块也很多

Nginx的缺点是：

1、Nginx仅能支持http、https和Email协议，这样就在适用范围上面小些，这个是它的缺点

2、对后端服务器的健康检查，只支持通过端口来检测，不支持通过url来检测
不支持Session的直接保持，但能通过ip_hash来解决
LVS：使用Linux内核集群实现一个高性能、高可用的负载均衡服务器
它具有很好的可伸缩性（Scalability)、可靠性（Reliability)和可管理性（Manageability)

LVS的优点是：

1、抗负载能力强、是工作在网络4层之上仅作分发之用，没有流量的产生，这个特点也决定了它在负载均衡软件里的性能最强的，对内存和cpu资源消耗比较低
2、配置性比较低，这是一个缺点也是一个优点，因为没有可太多配置的东西，所以并不需要太多接触，大大减少了人为出错的几率
3、工作稳定，因为其本身抗负载能力很强，自身有完整的双机热备方案，如LVS+Keepalived，不过我们在项目实施中用得最多的还是LVS/DR+Keepalived
4、无流量，LVS只分发请求，而流量并不从它本身出去，这点保证了均衡器IO的性能不会收到大流量的影响。
5、应用范围较广，因为LVS工作在4层，所以它几乎可对所有应用做负载均衡，包括http、数据库、在线聊天室等

LVS的缺点是：

1、软件本身不支持正则表达式处理，不能做动静分离，而现在许多网站在这方面都有较强的需求，这个是Nginx/HAProxy+Keepalived的优势所在
2、如果是网站应用比较庞大的话，LVS/DR+Keepalived实施起来就比较复杂了，特别后面有Windows Server的机器的话，如果实施及配置还有维护过程就比较复杂了

HAProxy的特点是：

1、HAProxy也是支持虚拟主机的。
2、HAProxy的优点能够补充Nginx的一些缺点，比如支持Session的保持，Cookie的引导，同时支持通过获取指定的url来检测后端服务器的状态
3、HAProxy跟LVS类似，本身就只是一款负载均衡软件，单纯从效率上来讲HAProxy会比Nginx有更出色的负载均衡速度，在并发处理上也是优于Nginx的
4、HAProxy支持TCP协议的负载均衡转发，可以对MySQL读进行负载均衡对后端的MySQL节点进行检测和负载均衡，大家可以用LVS+Keepalived对MySQL主从做负载均衡
5、HAProxy负载均衡策略非常多，HAProxy的负载均衡算法现在具体有如下8种：

①roundrobin，表示简单的轮询，这个不多说，这个是负载均衡基本都具备的；
② static-rr，表示根据权重，建议关注；
③leastconn，表示最少连接者先处理，建议关注；
④ source，表示根据请求源IP，这个跟Nginx的IP_hash机制类似我们用其作为解决session问题的一种方法，建议关注；
⑤ri，表示根据请求的URI；
⑥rl_param，表示根据请求的URl参数’balance url_param’ requires an URL parameter name；
⑦hdr(name)，表示根据HTTP请求头来锁定每一次HTTP请求；
⑧rdp-cookie(name)，表示根据据cookie(name)来锁定并哈希每一次TCP请求。


5、讲述一下LVS三种模式的工作过程？
一、NAT模式（VS-NAT）

原理：就是把客户端发来的数据包的IP头的目的地址，在负载均衡器上换成其中一台RS的IP地址
并发至此RS来处理,RS处理完后把数据交给负载均衡器,负载均衡器再把数据包原IP地址改为自己的IP
将目的地址改为客户端IP地址即可期间,无论是进来的流量,还是出去的流量,都必须经过负载均衡器

优点：集群中的物理服务器可以使用任何支持TCP/IP操作系统，只有负载均衡器需要一个合法的IP地址
缺点：扩展性有限。当服务器节点（普通PC服务器）增长过多时,负载均衡器将成为整个系统的瓶颈
因为所有的请求包和应答包的流向都经过负载均衡器。当服务器节点过多时
大量的数据包都交汇在负载均衡器那，速度就会变慢！

二、IP隧道模式（VS-TUN）
原理：首先要知道，互联网上的大多Internet服务的请求包很短小，而应答包通常很大
那么隧道模式就是，把客户端发来的数据包，封装一个新的IP头标记(仅目的IP)发给RS
RS收到后,先把数据包的头解开,还原数据包,处理后,直接返回给客户端,不需要再经过
负载均衡器。注意,由于RS需要对负载均衡器发过来的数据包进行还原,所以说必须支持
IPTUNNEL协议，所以,在RS的内核中,必须编译支持IPTUNNEL这个选项

优点：负载均衡器只负责将请求包分发给后端节点服务器，而RS将应答包直接发给用户
所以，减少了负载均衡器的大量数据流动，负载均衡器不再是系统的瓶颈，就能处理很巨大的请求量
这种方式，一台负载均衡器能够为很多RS进行分发。而且跑在公网上就能进行不同地域的分发。

缺点：隧道模式的RS节点需要合法IP，这种方式需要所有的服务器支持”IP Tunneling”
(IP Encapsulation)协议，服务器可能只局限在部分Linux系统上

三、直接路由模式（VS-DR）
原理：负载均衡器和RS都使用同一个IP对外服务但只有DR对ARP请求进行响应
所有RS对本身这个IP的ARP请求保持静默也就是说,网关会把对这个服务IP的请求全部定向给DR
而DR收到数据包后根据调度算法,找出对应的RS,把目的MAC地址改为RS的MAC（因为IP一致）
并将请求分发给这台RS这时RS收到这个数据包,处理完成之后，由于IP一致，可以直接将数据返给客户
则等于直接从客户端收到这个数据包无异,处理后直接返回给客户端
由于负载均衡器要对二层包头进行改换,所以负载均衡器和RS之间必须在一个广播域
也可以简单的理解为在同一台交换机上

优点：和TUN（隧道模式）一样，负载均衡器也只是分发请求，应答包通过单独的路由方法返回给客户端
与VS-TUN相比，VS-DR这种实现方式不需要隧道结构，因此可以使用大多数操作系统做为物理服务器。
缺点：（不能说缺点，只能说是不足）要求负载均衡器的网卡必须与物理网卡在一个物理段上。


        proxy_set_header Host       $http_host;
        proxy_set_header X-Real-IP  $remote_addr;
        proxy_set_header x-forwarded-for $proxy_add_x_forwarded_for;


31、你常用的Nginx模块，用来做什么

rewrite模块，实现重写功能
access模块：来源控制
ssl模块：安全加密
ngx_http_gzip_module：网络传输压缩模块
ngx_http_proxy_module 模块实现代理
ngx_http_upstream_module模块实现定义后端服务器列表
ngx_cache_purge实现缓存清除功能


1： Deployment
2： StatefulSet
3： DaemonSet
4：Job
5： CronJob



如果你对Prometheus没有接触过，也许会看不懂上面说什么，但是没关系，如果你看完之后，在回过头来瞧瞧，也许就了解这个架构了，也会对Prometheus有一个更深的认识。
这里简单说一下Prometheus的各个部分。
Prometheus Server: Prometheus服务端，由于存储及收集数据，提供相关api对外查询用。
Exporter: 类似传统意义上的被监控端的agent，有区别的是，它不会主动推送监控数据到server端，而是等待server端定时来手机数据，即所谓的主动监控。
Pushagateway: 用于网络不可直达而居于exporter与server端的中转站。
Alertmanager: 报警组件，将报警的功能单独剥离出来放在alertmanager。
Web UI: Prometheus的web接口，可用于简单可视化，及语句执行或者服务状态监控。


具有由 metric 名称和键/值对标识的时间序列数据的多维数据模型
PromQL，有一个灵活的查询语言
不依赖分布式存储，只和本地磁盘有关
通过 HTTP 的服务拉取时间序列数据
也支持推送的方式来添加时间序列数据
通过服务发现或静态配置发现目标
多种图形和仪表板支持


 配置告警对象有两种方式,一种是通过静态文件配置,另一种是动态发现机制,自动完成 数据采集。


autoscaling/v1：只支持基于CPU指标的缩放；

autoscaling/v2beta1：支持Resource Metrics（资源指标，如pod的CPU）和Custom Metrics（自定义指标）的缩放；

autoscaling/v2beta2：支持Resource Metrics（资源指标，如pod的CPU）和Custom Metrics（自定义指标）和ExternalMetrics（额外指标）的缩放。


kubectl autoscale deployment nginx --min=1 --max=5 --cpu-percent=80


Calico网络方式（两种）
1）IPIP
从字面来理解，就是把一个IP数据包又套在一个IP包里，即把 IP 层封装到 IP 层的一个 tunnel，看起来似乎是浪费，实则不然。它的作用其实基本上就相当于一个基于IP层的网桥！一般来说，普通的网桥是基于mac层的，根本不需 IP，而这个 ipip 则是通过两端的路由做一个 tunnel，把两个本来不通的网络通过点对点连接起来。ipip 的源代码在内核 net/ipv4/ipip.c 中可以找到。

2）BGP
边界网关协议（Border Gateway Protocol, BGP）是互联网上一个核心的去中心化自治路由协议。它通过维护IP路由表或‘前缀’表来实现自治系统（AS）之间的可达性，属于矢量路由协议。BGP不使用传统的内部网关协议（IGP）的指标，而使用基于路径、网络策略或规则集来决定路由。因此，它更适合被称为矢量性协议，而不是路由协议。BGP，通俗的讲就是讲接入到机房的多条线路（如电信、联通、移动等）融合为一体，实现多线单IP，BGP 机房的优点：服务器只需要设置一个IP地址，最佳访问路由是由网络上的骨干路由器根据路由跳数与其它技术指标来确定的，不会占用服务器的任何系统。




















