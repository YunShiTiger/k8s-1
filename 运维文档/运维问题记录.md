#### 1、k8s集群环境，docker拉取镜像: Cannot allocate memory

**问题**

测试环境拉取镜像cannot allocate memory

**排查过程**：

进程数并没满，然后排查相关组键问题，k8s采用的二进制部署，因而与docker相关的组件有kubelet与flanld以及docker版本有关，测试发现更换版本并未解决问题；测试发现停掉flanld服务，重启主机，还是不能拉取镜像，关闭kubelet服务，重启主机，发现可以正常拉取镜像，因此排查出kubelet影响了镜像的拉取，经排查相应配置时发现一些久配置（已弃用），怀疑与这些旧配置影响镜像拉取

**解决**

剔除旧配置，重启服务，可以正常拉取。

![](../acess/16293593634202.png)

![image-20210826112838607](../acess/image-20210826112838607.png)

#### 2、非443端口启用https

需要添加以下配置，否则应用访问不了

```
ssl on;
```

#### 3、kubelet报错

**问题**

通过 journalctl -u kubelet -f 命令看kubelet日志,就没有 Orphaned pod found - but volume paths are still present on disk报错

**排查**

通过`journalctl -u kubelet -f`发现一直在报以上错误，从错误信息可以推测出，这台节点存在一个孤立的Pod，并且该Pod挂载了数据卷(volume)，阻碍了Kubelet对孤立的Pod正常回收清理.kubelet 默认把一些数据信息存放在 `/var/lib/kubelet` 目录下，通过 `Pod Id`能查找到pod 挂载的数据。

**解决**

通过查看 `etc-hosts` 文件的 `pod name` 名称，查看集群中是否还有相关实例在运行，如果没有直接删除

或者重启kubelet

#### 4、docker-compose起不来

Cannot start service backup-beta: OCI runtime create failed: container_linux.go:367: starting container process caused: process_linux.go:352: getting the final child's pid from pipe caused: EOF: unknown

根据报错，查看版本号无差异

free -m 查看发现free较少，buff较多，因资源限定，导致起不来，清除buff，重新启动可以正常运行

#### 5、1 node(s) had taint {node.kubernetes.io/disk-pressure: }, that the pod didn‘t tolerate

基于污点的驱逐 ：   

当某种条件为真时，节点控制器会自动给节点添加一个污点。当前内置的污点包括：

node.kubernetes.io/not-ready：节点未准备好。这相当于节点状态 Ready 的值为 "False"。
node.kubernetes.io/unreachable：节点控制器访问不到节点. 这相当于节点状态 Ready 的值为 "Unknown"。
node.kubernetes.io/memory-pressure：节点存在内存压力。
node.kubernetes.io/disk-pressure：节点存在磁盘压力。
node.kubernetes.io/pid-pressure: 节点的 PID 压力。
node.kubernetes.io/network-unavailable：节点网络不可用。
node.kubernetes.io/unschedulable: 节点不可调度。
node.cloudprovider.kubernetes.io/uninitialized：如果 kubelet 启动时指定了一个 "外部" 云平台驱动， 它将给当前节点添加一个污点将其标志为不可用。在 cloud-controller-manager 的一个控制器初始化这个节点后，kubelet 将删除这个污点。

**解决方法：**

​    node上的kubelet负责采集资源占用数据，并和预先设置的threshold值进行比较，如果超过threshold值，kubelet会杀掉一些Pod来回收相关资源。

​    清除磁盘，重启pod，发现并不能创建pod，该节点的污点并不会自动取消，重启kubelet，可以看到pod启动。
